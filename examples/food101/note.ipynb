{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food-101 整理出小测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train origin len: 68175 | 101 101 101\n",
      "train labeled len: 61307\n",
      "train unlabeled len: 6868\n",
      "----------------\n",
      "test origin len: 25250 | 101 101 101\n",
      "test labeled len: 22725\n",
      "test unlabeled len: 2525\n",
      "----------------\n",
      "val origin len: 7575 | 101 101 101\n",
      "val labeled len: 6767\n",
      "val unlabeled len: 808\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "root = Path('/www/datasets/') / 'Ingredients101'\n",
    "# image_dir = root / 'ready_chinese_food'\n",
    "label_dir = root / 'Annotations'\n",
    "num_classes = 101\n",
    "ratio = 0.9\n",
    "for split in ['train', 'test', 'val']:\n",
    "    label_file = label_dir / f\"{split}_labels.txt\"\n",
    "    image_file = label_dir / f\"{split}_images.txt\"\n",
    "\n",
    "    all_labels = {}\n",
    "    all_images = {}\n",
    "    num_data = 0\n",
    "\n",
    "    all_images_list = []\n",
    "    with open(image_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            _line = line.rstrip()\n",
    "            all_images_list.append(_line)\n",
    "\n",
    "    all_labels_list = []\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            _line = line.rstrip()\n",
    "            all_labels_list.append(_line)\n",
    "\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            _line = line.rstrip()\n",
    "            if _line not in all_labels:\n",
    "                all_labels[_line] = []\n",
    "                all_images[_line] = []\n",
    "            all_images[_line].append(all_images_list[num_data])\n",
    "            #  |\n",
    "            #  V\n",
    "            all_labels[_line].append(all_labels_list[num_data])\n",
    "            num_data += 1\n",
    "    \n",
    "    print(f'{split} origin len:', num_data, '|', len(all_labels.keys()), len(all_images.keys()), num_classes)\n",
    "    assert len(all_labels.keys()) == len(all_images.keys()) == num_classes\n",
    "    \n",
    "    num = int(num_data * ratio)\n",
    "    \n",
    "    labeled_images = []\n",
    "    unlabeled_images = []\n",
    "    labeled_labels = []\n",
    "    unlabeled_labels = []\n",
    "    threshold = num // num_classes\n",
    "    for _label in all_labels.keys():\n",
    "        labeled_images.extend(all_images[_label][:threshold])\n",
    "        unlabeled_images.extend(all_images[_label][threshold:])\n",
    "\n",
    "        labeled_labels.extend(all_labels[_label][:threshold])\n",
    "        unlabeled_labels.extend(all_labels[_label][threshold:])\n",
    "\n",
    "    # print('==> split:', split, 'ratio:', ratio, 'num:', num, 'threshold:', threshold, len(labeled_images))\n",
    "    assert len(labeled_images) == len(labeled_labels)\n",
    "    assert len(unlabeled_images) == len(unlabeled_labels)\n",
    "    print(f'{split} labeled len:', len(labeled_images))\n",
    "    print(f'{split} unlabeled len:', len(unlabeled_images))\n",
    "    print('----------------')\n",
    "    \n",
    "    labeled_image_filename = f'labeled_{int(ratio*100)}_{split}_images.txt'\n",
    "    unlabeled_image_filename = f'unlabeled_{int(ratio*100)}_{split}_images.txt'\n",
    "\n",
    "    # save to txt file\n",
    "    with open(label_dir / labeled_image_filename, 'w') as f:\n",
    "        for image in labeled_images:\n",
    "            f.write(str(image) + '\\n')\n",
    "\n",
    "    with open(label_dir / unlabeled_image_filename, 'w') as f:\n",
    "        for image in unlabeled_images:\n",
    "            f.write(str(image) + '\\n')\n",
    "\n",
    "    labeled_label_filename = f'labeled_{int(ratio*100)}_{split}_labels.txt'\n",
    "    unlabeled_label_filename = f'unlabeled_{int(ratio*100)}_{split}_labels.txt'\n",
    "\n",
    "    # save to txt file\n",
    "    with open(label_dir / labeled_label_filename, 'w') as f:\n",
    "        for label in labeled_labels:\n",
    "            f.write(str(label) + '\\n')\n",
    "\n",
    "    with open(label_dir / unlabeled_label_filename, 'w') as f:\n",
    "        for label in unlabeled_labels:\n",
    "            f.write(str(label) + '\\n')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from create_dataset import Food172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "food172 = Food172('/www/datasets/Food172', sub_labels=[0, 308])\n",
    "image_ingredient_label_map = food172.image_ingredient_label_map\n",
    "\n",
    "# ingredient_label_names\n",
    "# ingredient_label_names = food172.ingredient_label_names\n",
    "print(len(image_ingredient_label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_label_names = food172.ingredient_label_names\n",
    "print(ingredient_label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个食材出现的次数\n",
    "ingredient_count = {}\n",
    "for image_name, ingredient_label in image_ingredient_label_map.items():\n",
    "    for i, label in enumerate(ingredient_label):\n",
    "        if label == 1:\n",
    "            if i not in ingredient_count:\n",
    "                ingredient_count[i] = 1\n",
    "            else:\n",
    "                ingredient_count[i] += 1\n",
    "# pprint(ingredient_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ingredient_count = sorted(ingredient_count.items(), key=lambda x: x[1], reverse=True)\n",
    "pprint(sorted_ingredient_count[:1])\n",
    "pprint(sorted_ingredient_count[-1:])\n",
    "# ingredient_name_count\n",
    "ingredient_name_count = {}\n",
    "for i, count in ingredient_count.items():\n",
    "    ingredient_name_count[ingredient_label_names[i]] = count\n",
    "\n",
    "# print ingredient_name_count with top 10\n",
    "sorted_ingredient_name_count = sorted(ingredient_name_count.items(), key=lambda x: x[1], reverse=True)\n",
    "# pprint(sorted_ingredient_name_count[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks={'dish pred': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ''\n",
    "b = a.split(',').remove('')\n",
    "# b.remove('')\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个字符串，包含函数代码\n",
    "func_str = \"def add(x, y):\\n    return x + y\"\n",
    "\n",
    "# 使用 eval() 函数将字符串转换为函数\n",
    "add_func = eval(func_str)\n",
    "\n",
    "# 调用函数\n",
    "result = add_func(2, 3)\n",
    "\n",
    "# 输出结果\n",
    "print(result) # 输出 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from create_dataset import Food172\n",
    "\n",
    "\n",
    "data_prefix = 'sub_50_'\n",
    "sub_labels = []\n",
    "dataset_path = '/www/datasets/Food172'\n",
    "num_classes = 172\n",
    "\n",
    "food172_train_set = Food172(root=dataset_path, prefix=data_prefix, \n",
    "                            sub_labels=sub_labels, mode='trainval',\n",
    "                            augmentation=False)\n",
    "\n",
    "# 根据 train set 构建知识图谱\n",
    "multiclass_label = food172_train_set.multiclass # food标签 [1, 0, 2, ......, 171, 171, 171]\n",
    "multilabel_label = food172_train_set.multilabel # 食材标签 [[0, 1, 1, ..., 0], [0, 1, 1, ..., 1], [0, 1, 1, ..., 1], ..., [0, 1, 1, ..., 1]]\n",
    "\n",
    "assert len(multiclass_label) == len(multilabel_label)\n",
    "\n",
    "pd_multiclass_label = pd.DataFrame(multiclass_label)\n",
    "pd_multilabel_label = pd.DataFrame(multilabel_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设你有一个 DataFrame df，大小为 (516, 1)\n",
    "# 创建一个示例 DataFrame\n",
    "data = {'column_name': [0, 2, 1, 3, 2, 0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 查找值为 i 的索引\n",
    "i = 2\n",
    "indices = df[df['column_name'] == i].index\n",
    "\n",
    "print(df['column_name'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar index: 94\n",
      "Similarity value: 0.7931146621704102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def find_most_similar_vector(a, b):\n",
    "    # 计算 a 和 b 之间的余弦相似度\n",
    "    similarity_scores = F.cosine_similarity(a, b.unsqueeze(0), dim=1)\n",
    "    # 找到最相似向量的索引\n",
    "    most_similar_index = torch.argmax(similarity_scores)\n",
    "    # 获取相似度值\n",
    "    similarity_value = similarity_scores[most_similar_index]\n",
    "\n",
    "    return most_similar_index.item(), similarity_value.item()\n",
    "\n",
    "# 示例数据\n",
    "a = torch.rand(111, 227)\n",
    "b = torch.rand(227)\n",
    "\n",
    "# 查找最相似向量的索引和相似度值\n",
    "most_similar_index, similarity_value = find_most_similar_vector(a, b)\n",
    "print(\"Most similar index:\", most_similar_index)\n",
    "print(\"Similarity value:\", similarity_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4] [2 3 4]\n",
      "sorted_indices: [2 0 3 1 4]\n",
      "[3 4 5] [ 8  9 10]\n",
      "sorted_indices: [ 8  5  9  6 10  7]\n",
      "[ 6  7  8  9 10 11] [17 18 19 20 21 22]\n",
      "sorted_indices: [17 11 18 12 19 13 20 14 21 15 22 16]\n",
      "[-1  0 -1  0  0 -1  1  1 -1 -1  1 -1 -1 -1  2  2  2 -1 -1 -1  2  2  2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def insert_elements_interval(arr):\n",
    "    # 计算后半部分的起始索引\n",
    "    mid_index = len(arr) // 2\n",
    "    print(np.arange(mid_index, len(arr)), arr[mid_index:])\n",
    "\n",
    "    # 将后半部分的元素间隔插入前半部分\n",
    "    result = np.insert(arr[:mid_index], np.arange(0, len(arr[mid_index:])), arr[mid_index:])\n",
    "\n",
    "    return result\n",
    "\n",
    "def replace_with_percentage(data, percentage):\n",
    "    unique_elements = np.unique(data)\n",
    "    \n",
    "    for element in unique_elements:\n",
    "        indices = np.where(data == element)[0]\n",
    "        sorted_indices = insert_elements_interval(np.sort(indices))\n",
    "        print('sorted_indices:', sorted_indices)\n",
    "        # 将 sorted_indices 中的 第 len(sorted_indices)/2 个元素放在第 0 个元素后面，\n",
    "        num_to_replace = int(len(indices) * percentage)\n",
    "        indices_to_replace = sorted_indices[:num_to_replace]\n",
    "        data[indices_to_replace] = -1\n",
    "\n",
    "# 示例数据\n",
    "data = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "# 复制一份数据，保留原始数据不受影响\n",
    "a_copy = np.array(data)\n",
    "\n",
    "# 将各种类的元素的 20% 替换为 -1\n",
    "percentage = 0.5\n",
    "replace_with_percentage(a_copy, percentage)\n",
    "\n",
    "print(a_copy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libmtl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
